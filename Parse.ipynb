{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import csv\n",
    "import requests\n",
    "\n",
    "\n",
    "taxi_zone_lookup_chart = \"/home/erynqian/10701/19F10701_Project/taxi _zone_lookup.csv\"\n",
    "taxi_zone_geolocation_file = \"/home/erynqian/10701/19F10701_Project/taxi_zone_lookup.hdf5\"\n",
    "datafields = [\"VendorID\",\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"passenger_count\",\"PULocationID\",\"DOLocationID\",\"payment_type\"]\n",
    "key = \"6fW8tAG2L3VWCJYeKQ0IwgBzJNBJpoDZ\"\n",
    "\n",
    "Data = namedtuple(\"Data\", [\"start_hour\", \"date\", \"day_of_week\", \"isHoliday\", \n",
    "                           \"start_zone_latitude\", \"start_zone_longitude\", \n",
    "                           \"end_zone_latitude\", \"end_zone_longitude\", \"distance\", \"ETA\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fetch taxi zone geo coordinates from online API\"\"\"\n",
    "# with open(taxi_zone_lookup_chart) as csv_file:\n",
    "#     csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "#     first = 0\n",
    "#     for row in csv_reader:\n",
    "#         if first == 0:\n",
    "#             first += 1\n",
    "#         else:\n",
    "#             locationID, location = int(row[0]), row[1:]\n",
    "#             location = location[0] + \", \" + location[1]\n",
    "#             url = \"http://open.mapquestapi.com/geocoding/v1/address?key=\" + key + \"&location=\" + location\n",
    "#             response = requests.get(url)\n",
    "#             taxi_zone_lookup[locationID] = response.json()[\"results\"][0][\"locations\"][0][\"latLng\"]\n",
    "\n",
    "\"\"\"Store geo coordinates to hdf5 file\"\"\"\n",
    "# df = pd.read_csv(taxi_zone_lookup_chart, sep=',')\n",
    "# with h5py.File(taxi_zone_geolocation_file, \"w\") as f:\n",
    "#     dset = f.create_dataset(\"taxi_zone_geolocation\", (len(df), 3), dtype='f')\n",
    "#     for i in range(1, len(df)+1):\n",
    "#         dset[i-1] = [i, taxi_zone_lookup[i][\"lat\"], taxi_zone_lookup[i][\"lng\"]]\n",
    "\n",
    "\"\"\"Look up latitude and longitude of the taxi zone of given index\"\"\"\n",
    "def lookup_taxi_zone(index):\n",
    "    with h5py.File(taxi_zone_geolocation_file, \"r\") as f:\n",
    "        dset = f[\"taxi_zone_geolocation\"]\n",
    "        _, lat, lng = dset[index-1]\n",
    "        return lat, lng\n",
    "\n",
    "\n",
    "# TEST\n",
    "# for i in range(1, 266):\n",
    "#     print(i, lookup_taxi_zone(i))\n",
    "# print(lookup_taxi_zone(265))\n",
    "# print(lookup_taxi_zone(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "start_hour : 0\ndate : 211\nday_of_week : 0\nisHoliday : 0\nstart_zone_latitude : 40.748158\nstart_zone_longitude : -73.97875\nend_zone_latitude : 40.757324\nend_zone_longitude : -73.995415\ndistance : 0.0003616708709159866\nETA : 12.2\n"
    }
   ],
   "source": [
    "class ParsedData:\n",
    "\n",
    "    def __init__(self, row):\n",
    "        self.row = row\n",
    "    \n",
    "    def start_hour(self):\n",
    "        start_time = self.row[1].split(' ')[1]\n",
    "        start_hour = start_time.split(':')[0]\n",
    "        return int(start_hour)\n",
    "    \n",
    "    def date(self):\n",
    "        \"\"\"represent date as the kth day of the year; return k as int\"\"\"\n",
    "        date = self.row[1].split(' ')[0]\n",
    "        y,m,d = date.split('-')\n",
    "        days_in_feb = 29 if int(y) % 4 == 0 else 28\n",
    "        days_in_month = {1:31, 2:days_in_feb, 3:31, 4:30, 5:31, 6:30, 7:31, 8:31, 9:30, 10:31, 11:30, 12:31}\n",
    "        return sum([days_in_month[i] for i in range(1, int(m))]) + int(d)\n",
    "\n",
    "    def day_of_week(self):\n",
    "        date = self.row[1].split(' ')[0]\n",
    "        y,m,d = [int(i) for i in date.split('-')]\n",
    "        t = [ 0, 3, 2, 5, 0, 3, 5, 1, 4, 6, 2, 4 ] \n",
    "        y -= m < 3\n",
    "        return (( y + int(y / 4) - int(y / 100) + int(y / 400) + t[m - 1] + d) % 7) \n",
    "\n",
    "    def isHoliday(self):\n",
    "        \"\"\"    \n",
    "        National holidays only\n",
    "        reference: https://www.officeholidays.com/countries/usa/2017\n",
    "                   https://www.officeholidays.com/countries/usa/2018\n",
    "        \"\"\"\n",
    "        holidays2017 = [[1,2], [1,16], [5,29], [7,4], [9,4], [11,23], [12,25]]\n",
    "        holidays2018 = [[1,1], [1,15], [5,28], [7,4], [9,3], [11,22], [12,25]]\n",
    "        date = self.row[1].split(' ')[0]\n",
    "        y,m,d = [int(i) for i in date.split('-')]\n",
    "        holidays = holidays2017 if y == 2017 else holidays2018\n",
    "        for h in holidays:\n",
    "            if m == h[0] and d == h[1]:\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def start_end_distance(self):\n",
    "        \"\"\"return 4 coordinates: start_latitude, start_longitude, end_latitude, end_longitude\"\"\"\n",
    "        pickup, dropoff = int(self.row[4]), int(self.row[5])\n",
    "        PU_lat, PU_lng = lookup_taxi_zone(pickup)\n",
    "        DO_lat, DO_lng = lookup_taxi_zone(dropoff)\n",
    "        distance = (PU_lat - DO_lat) ** 2 + (PU_lng - DO_lng) ** 2\n",
    "        return [PU_lat, PU_lng, DO_lat, DO_lng, distance]\n",
    "\n",
    "    def ETA(self):\n",
    "        \"\"\"return ETA in min\"\"\"\n",
    "        start = self.row[1].split(' ')[1].split(':')\n",
    "        end = self.row[2].split(' ')[1].split(':')\n",
    "        hour_diff = int(end[0]) - int(start[0])\n",
    "        min_diff = int(end[1]) - int(start[1])\n",
    "        sec_diff = int(end[1]) - int(start[1])\n",
    "        return hour_diff * 60 + min_diff + round(sec_diff / 60, 3)\n",
    "\n",
    "    def data(self):\n",
    "        return [self.start_hour(), self.date(), self.day_of_week(), self.isHoliday()] + \\\n",
    "                self.start_end_distance() + [self.ETA()]\n",
    "\n",
    "\n",
    "# TEST\n",
    "entry = ['1', '2017-07-30 00:27:25', '2017-07-30 00:39:09', '1', '170', '48', '1']\n",
    "d = ParsedData(entry)\n",
    "for field, data in zip(Data._fields, d.data()):\n",
    "    print(field, \":\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"parse csv\"\"\"\n",
    "filename = \"/home/erynqian/10701/19F10701_Project/testData/assignment1_data-1.csv\"\n",
    "\n",
    "def parse_csv(filename):\n",
    "    print(\"processing\", filename.split('/')[-1], \"...\")\n",
    "    df = pd.read_csv(filename, sep=',')\n",
    "    file_len = len(df)\n",
    "    data_len = len(Data._fields)\n",
    "\n",
    "    hdf5_filename = filename.split('.')[0] + '.hdf5'\n",
    "    with h5py.File(hdf5_filename, \"w\") as f:\n",
    "        dset = f.create_dataset(\"mydataset\", (file_len, data_len), dtype='f')\n",
    "        parsedData = 0\n",
    "\n",
    "        with open(filename) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            r = -1\n",
    "            for row in csv_reader:\n",
    "                if r == -1: #skip first line\n",
    "                    r += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    parsedData = ParsedData(row)\n",
    "                    dset[r, :] = parsedData.data()\n",
    "                    r += 1\n",
    "                if r % 10000 == 0:\n",
    "                    print(r, \"rows processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"/home/erynqian/10701/19F10701_Project/testData/assignment1_data-1.csv\",\n",
    "\"/home/erynqian/10701/19F10701_Project/testData/assignment1_data-90.csv\",\n",
    "\"/home/erynqian/10701/19F10701_Project/testData/assignment1_data-140.csv\",\n",
    "\"/home/erynqian/10701/19F10701_Project/testData/assignment1_data-629.csv\",\n",
    "\"/home/erynqian/10701/19F10701_Project/testData/assignment1_data-664.csv\"]\n",
    "\n",
    "# for filename in files:\n",
    "#     parse_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/home/erynqian/10701/19F10701_Project/testData/assignment1_data-1.hdf5\n(99999, 10)\n[[   0.        211.          0.          0.         39.78373  -100.445885\n    42.71777   -78.967255  469.94016    28.467   ]\n [   0.        211.          0.          0.         39.78373  -100.445885\n    40.772015  -73.93027   704.0547     18.3     ]\n [   0.        211.          0.          0.         39.54194  -119.7895\n    39.78373  -100.445885  374.23383     3.05    ]]\n[[ 1.20000000e+01  2.11000000e+02  0.00000000e+00  0.00000000e+00\n   4.07556648e+01 -7.40005493e+01  4.07870445e+01 -7.39754181e+01\n   1.61626399e-03  1.32170000e+01]\n [ 1.20000000e+01  2.11000000e+02  0.00000000e+00  0.00000000e+00\n   4.07556648e+01 -7.40005493e+01  4.07481575e+01 -7.39787521e+01\n   5.31476981e-04  1.32329998e+01]\n [ 1.20000000e+01  2.11000000e+02  0.00000000e+00  0.00000000e+00\n   3.95419388e+01 -1.19789497e+02  3.97837296e+01 -1.00445885e+02\n   3.74233826e+02  1.01669998e+01]]\n/home/erynqian/10701/19F10701_Project/testData/assignment1_data-90.hdf5\n(99999, 10)\n[[ 1.4000000e+01  2.9000000e+01  0.0000000e+00  0.0000000e+00\n   4.0737926e+01 -7.3985931e+01  4.0773544e+01 -7.3958733e+01\n   2.0084039e-03  1.0167000e+01]\n [ 1.4000000e+01  2.9000000e+01  0.0000000e+00  0.0000000e+00\n   4.0773544e+01 -7.3958733e+01  4.0773544e+01 -7.3958733e+01\n   0.0000000e+00  3.0500000e+00]\n [ 1.4000000e+01  2.9000000e+01  0.0000000e+00  0.0000000e+00\n   4.0773102e+01 -7.3981522e+01  4.0773102e+01 -7.3981522e+01\n   0.0000000e+00  4.0669999e+00]]\n[[ 2.30000000e+01  2.80000000e+01  6.00000000e+00  0.00000000e+00\n   4.07731018e+01 -7.39815216e+01  3.97837296e+01 -1.00445885e+02\n   7.01341370e+02  7.11700010e+00]\n [ 2.30000000e+01  2.80000000e+01  6.00000000e+00  0.00000000e+00\n   4.07566566e+01 -7.39987564e+01  4.08241463e+01 -7.39500656e+01\n   6.92564296e-03  1.62670002e+01]\n [ 2.30000000e+01  2.80000000e+01  6.00000000e+00  0.00000000e+00\n   4.07870445e+01 -7.39754181e+01  4.07292671e+01 -7.39873581e+01\n   3.48079205e-03 -1.41659998e+03]]\n/home/erynqian/10701/19F10701_Project/testData/assignment1_data-140.hdf5\n(99999, 10)\n[[  21.         38.          2.          0.         39.78373  -100.445885\n    39.78373  -100.445885    0.          9.15    ]\n [  21.         38.          2.          0.         40.79028   -73.959724\n    39.78373  -100.445885  702.52985    13.217   ]\n [  21.         38.          2.          0.         39.54194  -119.7895\n    39.78373  -100.445885  374.23383    16.267   ]]\n[[   9.         37.          1.          0.         40.773544  -73.95873\n    39.78373  -100.445885  702.54895    25.417   ]\n [   9.         37.          1.          0.         40.737926  -73.98593\n    39.78373  -100.445885  701.0396     12.2     ]\n [   9.         37.          1.          0.         40.787846  -73.954865\n    39.78373  -100.445885  702.7824     13.217   ]]\n/home/erynqian/10701/19F10701_Project/testData/assignment1_data-629.hdf5\n(99999, 10)\n[[ 1.7000000e+01  1.9500000e+02  5.0000000e+00  0.0000000e+00\n   4.0728436e+01 -7.4002914e+01  4.0757324e+01 -7.3995415e+01\n   8.9080253e-04  3.4583000e+01]\n [ 1.7000000e+01  1.9500000e+02  5.0000000e+00  0.0000000e+00\n   3.9541939e+01 -1.1978950e+02  4.0773544e+01 -7.3958733e+01\n   2.1019758e+03  1.7283001e+01]\n [ 1.7000000e+01  1.9500000e+02  5.0000000e+00  0.0000000e+00\n   4.0773544e+01 -7.3958733e+01  4.0773544e+01 -7.3958733e+01\n   0.0000000e+00  1.1183000e+01]]\n[[ 2.30000000e+01  1.95000000e+02  5.00000000e+00  0.00000000e+00\n   3.97837296e+01 -1.00445885e+02  4.07735443e+01 -7.39587326e+01\n   7.02548950e+02  7.11700010e+00]\n [ 2.30000000e+01  1.95000000e+02  5.00000000e+00  0.00000000e+00\n   4.07564583e+01 -7.39925232e+01  4.07573242e+01 -7.39954147e+01\n   9.11085226e-06  9.14999962e+00]\n [ 2.30000000e+01  1.95000000e+02  5.00000000e+00  0.00000000e+00\n   4.07481575e+01 -7.39787521e+01  4.06942711e+01 -7.39187469e+01\n   6.50436804e-03 -1.40744995e+03]]\n/home/erynqian/10701/19F10701_Project/testData/assignment1_data-664.hdf5\n(99999, 10)\n[[ 1.80000000e+01  2.07000000e+02  3.00000000e+00  0.00000000e+00\n   4.07642326e+01 -7.39636459e+01  4.07878456e+01 -7.39548645e+01\n   6.34686206e-04  5.08300018e+00]\n [ 1.80000000e+01  2.07000000e+02  3.00000000e+00  0.00000000e+00\n   4.07878456e+01 -7.39548645e+01  4.07159348e+01 -7.39868088e+01\n   6.19160803e-03  2.74500008e+01]\n [ 1.80000000e+01  2.07000000e+02  3.00000000e+00  0.00000000e+00\n   3.97837296e+01 -1.00445885e+02  4.07789154e+01 -7.39541702e+01\n   7.02801331e+02  1.01669998e+01]]\n[[   0.        208.          4.          0.         40.728436  -74.002914\n    39.78373  -100.445885  700.12317    10.167   ]\n [   0.        208.          4.          0.         39.78373  -100.445885\n    39.78373  -100.445885    0.          9.167   ]\n [   0.        208.          4.          0.         35.52909  -114.91008\n    40.773544  -73.95873  1704.5171     21.35    ]]\n"
    }
   ],
   "source": [
    "# TEST\n",
    "for filename in files:\n",
    "    hdf5_filename = filename.split('.')[0] + '.hdf5'\n",
    "    with h5py.File(hdf5_filename, \"r\") as f:\n",
    "        dset = f[\"mydataset\"]\n",
    "        print(hdf5_filename)\n",
    "        print(dset.shape)\n",
    "        print(dset[:3])\n",
    "        print(dset[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}