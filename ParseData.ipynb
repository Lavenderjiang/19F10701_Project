{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName= 'testData/assignment1_data-1.csv'\n",
    "df = pd.read_csv(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "Feature Removal\n",
    "1. payment_type not relevant, should be removed\n",
    "2. vendorID is administrative data, should be removed\n",
    "3. passenger count is irrelevant of travel time (assume single stop)\n",
    "Feature Processing\n",
    "1. Convert pickup datetime to: day-of-week, isHoliday, startHour, date (1-365)\n",
    "2. Convert PULocationID to: start_zone_latitude, start_zone_longitude\n",
    "3. convert DOLocationID to: end_zone_latitude, end_zone_longitude\n",
    "4. convert PULocationID,DOLocationID to distance (perhaps path distance?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0             1  2017-07-30 00:20:56   2017-07-30 00:48:20                1   \n",
      "1             1  2017-07-30 00:30:28   2017-07-30 00:48:10                1   \n",
      "2             2  2017-07-30 00:20:08   2017-07-30 00:23:58                5   \n",
      "3             2  2017-07-30 00:29:00   2017-07-30 00:32:40                5   \n",
      "4             2  2017-07-30 00:41:55   2017-07-30 01:08:30                5   \n",
      "...         ...                  ...                   ...              ...   \n",
      "99994         2  2017-07-30 12:54:52   2017-07-30 13:12:03                1   \n",
      "99995         1  2017-07-30 12:13:24   2017-07-30 12:18:14                1   \n",
      "99996         1  2017-07-30 12:29:29   2017-07-30 12:42:08                1   \n",
      "99997         1  2017-07-30 12:52:03   2017-07-30 13:06:24                1   \n",
      "99998         2  2017-07-30 12:25:49   2017-07-30 12:35:09                5   \n",
      "\n",
      "       PULocationID  DOLocationID  payment_type  \n",
      "0               138           265             2  \n",
      "1               161             7             1  \n",
      "2               164           161             2  \n",
      "3               229           233             1  \n",
      "4               137           244             2  \n",
      "...             ...           ...           ...  \n",
      "99994           138           146             1  \n",
      "99995           246            68             2  \n",
      "99996           246           239             1  \n",
      "99997           246           170             2  \n",
      "99998           164           230             1  \n",
      "\n",
      "[99999 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# convert datatime\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"HDF5Dataset.py\"\n",
    "\"\"\"\n",
    "Usage Example:a\n",
    "ds = HDF5Dataset(filename)\n",
    "len(ds)                   # find length of the dataset\n",
    "ds[10]                    # get 11th instance in the dataset\n",
    "ds[\"start_hour\"]          # get a column of start_hours of all instances \n",
    "ds[0][\"start_hour\"]       # get start_hour of the 1st instance in dataset\n",
    "ds.X()                    # get the X matrix: n x d\n",
    "ds.Y()                    # get the Y matrix: n x 1\n",
    "ds.W()                    # get the weight matrix: n x 1\n",
    "X, Y, W = ds()            # get all three matrices at once\n",
    "ds.features()             # get the list of features\n",
    "ds.num_of_features        # get the number of features \n",
    "\"\"\"\n",
    "\n",
    "import h5py\n",
    "from collections import namedtuple\n",
    "\n",
    "Data = namedtuple(\"Data\", [\"start_hour\", \"date\", \"day_of_week\", \"isHoliday\", \n",
    "                           \"start_zone_latitude\", \"start_zone_longitude\", \n",
    "                           \"end_zone_latitude\", \"end_zone_longitude\", \n",
    "                           \"price\", \"distance\", \"ETA\"])\n",
    "\n",
    "class HDF5Dataset:\n",
    "\n",
    "    def __init__(self, csv_filename):\n",
    "        self.dataset, self.save_dir = self.parse_file(csv_filename)\n",
    "        self.num_of_features = len(Data._fields) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get length of the dataset\"\"\"\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"Get single instance\"\"\"\n",
    "        if type(key) is int:\n",
    "            return Data._make(self.dataset[key])\n",
    "\n",
    "        \"\"\"Get single feature across all instances\"\"\"\n",
    "        try:\n",
    "            index = self.features().index(key)\n",
    "            return self.dataset[:, index]\n",
    "        except:\n",
    "            print(\"Undefined key value\")\n",
    "\n",
    "\n",
    "    def features(self):\n",
    "        \"\"\"Get data fields\"\"\"\n",
    "        return Data._fields\n",
    "\n",
    "    def X(self):\n",
    "        \"\"\"Get X matrix: n instances x d features\"\"\"\n",
    "        return self.dataset[:, : self.num_of_features]\n",
    "\n",
    "    def Y(self):\n",
    "        \"\"\"Get Y matrix: n instances x label\"\"\"\n",
    "        label_index = self.num_of_features\n",
    "        return self.dataset[:, label_index]\n",
    "\n",
    "    def W(self):\n",
    "        \"\"\"Get W matrix: n instances x weight (for weighted datapoints)\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.X(), self.Y(), self.W()\n",
    "\n",
    "    def parse_file(self, filename):\n",
    "        \"\"\"TODO(Eryn): parse raw csv file and return formatted hdf5 file (private method)\"\"\"\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:gcn]",
   "language": "python",
   "name": "conda-env-gcn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
